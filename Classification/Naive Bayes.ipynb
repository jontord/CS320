{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups \n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "\n",
    "# these are used to process the data\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking messages and placing them into classes based on words found \n",
    "# and probabilities calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the desired newsgroups\n",
    "newsgroup_names = ['comp.graphics', 'rec.sport.hockey', 'sci.electronics', 'sci.space']\n",
    "\n",
    "# getting the data\n",
    "newsgroups = fetch_20newsgroups(categories=newsgroup_names, shuffle=True, random_state=265)\n",
    "newsgroups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text into numbers for calculations\n",
    "word_vector = CountVectorizer()\n",
    "word_vector_counts = word_vector.fit_transform(newsgroups.data)\n",
    "\n",
    "# frequency of words: \n",
    "term_freq_transformer = TfidfTransformer()\n",
    "term_freq = term_freq_transformer.fit_transform(word_vector_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the Naive Bayes model\n",
    "model = MultinomialNB().fit(term_freq, newsgroups.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "\tThat GPU has amazing performance with a lot of shaders => comp.graphics\n",
      "\tThe player had a wicked slap shot => rec.sport.hockey\n",
      "\tI spent all day yesterday soldering banks of capacitors => sci.space\n",
      "\tToday I have to solder a bank of capacitors => sci.electronics\n",
      "\tNASA has rovers on Mars => sci.space\n",
      "Probabilities:\n",
      "comp.graphics    rec.sport.hockey sci.electronics  sci.space        \n",
      "0.29466149       0.22895149       0.24926344       0.22712357       \n",
      "0.12948055       0.51155698       0.18248712       0.17647535       \n",
      "0.18604814       0.24117771       0.27540452       0.29736963       \n",
      "0.21285086       0.21081302       0.3486507        0.22768541       \n",
      "0.079185633      0.066225915      0.10236622       0.75222223       \n"
     ]
    }
   ],
   "source": [
    "# Predict some new fake documents\n",
    "fake_docs = [\n",
    "    'That GPU has amazing performance with a lot of shaders',\n",
    "    'The player had a wicked slap shot',\n",
    "    'I spent all day yesterday soldering banks of capacitors',\n",
    "    'Today I have to solder a bank of capacitors',\n",
    "    'NASA has rovers on Mars']\n",
    "fake_counts = word_vector.transform(fake_docs)\n",
    "fake_term_freq = term_freq_transformer.transform(fake_counts)\n",
    "\n",
    "predicted = model.predict(fake_term_freq)\n",
    "print('Predictions:')\n",
    "for doc, group in zip(fake_docs, predicted):\n",
    "    print('\\t{0} => {1}'.format(doc, newsgroups.target_names[group]))\n",
    "\n",
    "probabilities = model.predict_proba(fake_term_freq)\n",
    "print('Probabilities:')\n",
    "print(''.join(['{:17}'.format(name) for name in newsgroups.target_names]))\n",
    "for probs in probabilities:\n",
    "    print(''.join(['{:<17.8}'.format(prob) for prob in probs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise Option Standard Difficulty\n",
    "\n",
    "# The Naive Bayes model found some key words in each of the phrases \n",
    "# and classified each message within certain catagories. For the \n",
    "# first message, I'm guessing that the use of \"GPU\" and \"shaders\" \n",
    "# were the key words. \n",
    "\n",
    "# Below are my own messages that fall within the given catagories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "\tThat graphics card is outdated by two years => comp.graphics\n",
      "\tThat player is such a bender => rec.sport.hockey\n",
      "\tI found the voltage of the closed circuit => sci.electronics\n",
      "\tWhat is the resistance in amps? => sci.electronics\n",
      "\tElon Musk plans to launch his car to Mars => sci.space\n",
      "Probabilities:\n",
      "comp.graphics    rec.sport.hockey sci.electronics  sci.space        \n",
      "0.4689949        0.15663217       0.20373913       0.1706338        \n",
      "0.14659586       0.42207164       0.21543725       0.21589525       \n",
      "0.1132552        0.081102297      0.67513708       0.13050542       \n",
      "0.13857652       0.15302762       0.53160645       0.17678941       \n",
      "0.076140732      0.13378088       0.16820211       0.62187628       \n"
     ]
    }
   ],
   "source": [
    "# Predict some new fake documents\n",
    "fake_docs = [\n",
    "    'That graphics card is outdated by two years',\n",
    "    'That player is such a bender',\n",
    "    'I found the voltage of the closed circuit',\n",
    "    'What is the resistance in amps?',\n",
    "    'Elon Musk plans to launch his car to Mars']\n",
    "fake_counts = word_vector.transform(fake_docs)\n",
    "fake_term_freq = term_freq_transformer.transform(fake_counts)\n",
    "\n",
    "predicted = model.predict(fake_term_freq)\n",
    "print('Predictions:')\n",
    "for doc, group in zip(fake_docs, predicted):\n",
    "    print('\\t{0} => {1}'.format(doc, newsgroups.target_names[group]))\n",
    "\n",
    "probabilities = model.predict_proba(fake_term_freq)\n",
    "print('Probabilities:')\n",
    "print(''.join(['{:17}'.format(name) for name in newsgroups.target_names]))\n",
    "for probs in probabilities:\n",
    "    print(''.join(['{:<17.8}'.format(prob) for prob in probs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I tried to use pretty obvious keywords such as \"graphics,\" but for \n",
    "# some reason, the probability for that specific example was less than\n",
    "# 50 percent. I also searched for hockey terms to create the second \n",
    "# example, but the model did not seem as confident as it did with the \n",
    "# electronics examples- 68 and 53 percent respectively. I'll try to \n",
    "# recreate this test with more obvious keywords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "\tI need a better CPU to render those high resolution graphics => comp.graphics\n",
      "\tThe centerman hit the puck straight down the rink => rec.sport.hockey\n",
      "\tI the voltage of the closed circuit and struggled to calculate the capacitance => sci.electronics\n",
      "\tWhat is the resistivity in amps of this circuit as a whole? => sci.electronics\n",
      "\tSpaceX created a self-landing spacecraft to optimize the reusability of their vehicles => sci.space\n",
      "Probabilities:\n",
      "comp.graphics    rec.sport.hockey sci.electronics  sci.space        \n",
      "0.48973754       0.098827902      0.25206809       0.15936647       \n",
      "0.10771924       0.54864512       0.16801594       0.1756197        \n",
      "0.16336696       0.15749811       0.50509739       0.17403754       \n",
      "0.12219006       0.15400576       0.55876542       0.16503876       \n",
      "0.16365548       0.16076378       0.17377995       0.5018008        \n"
     ]
    }
   ],
   "source": [
    "# Predict some new fake documents\n",
    "fake_docs = [\n",
    "    'I need a better CPU to render those high resolution graphics',\n",
    "    'The centerman hit the puck straight down the rink',\n",
    "    'I the voltage of the closed circuit and struggled to calculate the capacitance',\n",
    "    'What is the resistivity in amps of this circuit as a whole?',\n",
    "    'SpaceX created a self-landing spacecraft to optimize the reusability of their vehicles']\n",
    "fake_counts = word_vector.transform(fake_docs)\n",
    "fake_term_freq = term_freq_transformer.transform(fake_counts)\n",
    "\n",
    "# creating a small chart with the predictions and their probabilities\n",
    "\n",
    "predicted = model.predict(fake_term_freq)\n",
    "print('Predictions:')\n",
    "for doc, group in zip(fake_docs, predicted):\n",
    "    print('\\t{0} => {1}'.format(doc, newsgroups.target_names[group]))\n",
    "\n",
    "probabilities = model.predict_proba(fake_term_freq)\n",
    "print('Probabilities:')\n",
    "print(''.join(['{:17}'.format(name) for name in newsgroups.target_names]))\n",
    "for probs in probabilities:\n",
    "    print(''.join(['{:<17.8}'.format(prob) for prob in probs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, most of the probabilities lay around only about 50 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "\tGraphics => comp.graphics\n",
      "\tHockey => rec.sport.hockey\n",
      "\tElectronics => sci.electronics\n",
      "\tElectronics => sci.electronics\n",
      "\tSpace => sci.space\n",
      "Probabilities:\n",
      "comp.graphics    rec.sport.hockey sci.electronics  sci.space        \n",
      "0.83097207       0.050320841      0.060914262      0.057792827      \n",
      "0.045469352      0.86411871       0.045513981      0.044897959      \n",
      "0.11569539       0.10114255       0.63993689       0.14322517       \n",
      "0.11569539       0.10114255       0.63993689       0.14322517       \n",
      "0.058143513      0.037732506      0.046317148      0.85780683       \n"
     ]
    }
   ],
   "source": [
    "# Predict some new fake documents\n",
    "fake_docs = [\n",
    "    'Graphics',\n",
    "    'Hockey',\n",
    "    'Electronics',\n",
    "    'Electronics',\n",
    "    'Space']\n",
    "fake_counts = word_vector.transform(fake_docs)\n",
    "fake_term_freq = term_freq_transformer.transform(fake_counts)\n",
    "\n",
    "# creating a small chart with the predictions and their probabilities\n",
    "\n",
    "predicted = model.predict(fake_term_freq)\n",
    "print('Predictions:')\n",
    "for doc, group in zip(fake_docs, predicted):\n",
    "    print('\\t{0} => {1}'.format(doc, newsgroups.target_names[group]))\n",
    "\n",
    "probabilities = model.predict_proba(fake_term_freq)\n",
    "print('Probabilities:')\n",
    "print(''.join(['{:17}'.format(name) for name in newsgroups.target_names]))\n",
    "for probs in probabilities:\n",
    "    print(''.join(['{:<17.8}'.format(prob) for prob in probs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By only typing in the words that match the classnames, the probabilities \n",
    "# only increased to around 60 to 80 percent. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
